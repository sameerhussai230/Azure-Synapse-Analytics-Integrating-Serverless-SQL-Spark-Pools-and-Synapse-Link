{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Trip Data Aggregation \n",
        "### Group By Columns\n",
        "1. year\n",
        "2. Month\n",
        "3. Pickup Location ID\n",
        "4. Drop Off Location ID\n",
        "\n",
        "### Aggregated Columns\n",
        "1. Total Trip Count\n",
        "2. Total Fare Amount\n",
        "\n",
        "### Purpose of the notebook\n",
        "\n",
        "Demonstrate the integration between Spark Pool and Serverless SQL Pool\n",
        "\n",
        "1. Create the aggregated table in Spark Pool\n",
        "2. Access the data from Serverless SQL Pool "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "coursepool",
              "session_id": "0",
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-02-26T00:08:40.9756364Z",
              "session_start_time": "2024-02-26T00:08:41.0349516Z",
              "execution_start_time": "2024-02-26T00:12:03.4453747Z",
              "execution_finish_time": "2024-02-26T00:12:03.5994347Z",
              "spark_jobs": null,
              "parent_msg_id": "2a3a764b-0e71-422f-91c2-6746b6ac1773"
            },
            "text/plain": "StatementMeta(coursepool, 0, 2, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Set the folder paths so that it can be used later. \n",
        "bronze_folder_path = 'abfss://nyc-taxi-data@synapsecoursedlsam.dfs.core.windows.net/raw'\n",
        "silver_folder_path = 'abfss://nyc-taxi-data@synapsecoursedlsam.dfs.core.windows.net/silver'\n",
        "gold_folder_path = 'abfss://nyc-taxi-data@synapsecoursedlsam.dfs.core.windows.net/gold'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "coursepool",
              "session_id": "0",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-02-26T00:08:40.9763522Z",
              "session_start_time": null,
              "execution_start_time": "2024-02-26T00:12:03.7512737Z",
              "execution_finish_time": "2024-02-26T00:12:03.943574Z",
              "spark_jobs": null,
              "parent_msg_id": "44e02ba5-5cb1-4cd5-943d-0a56f6bdcdd3"
            },
            "text/plain": "StatementMeta(coursepool, 0, 3, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#Set the spark config to be able to get the partitioned columns year and month as strings rather than integers\n",
        "spark.conf.set(\"spark.sql.sources.partitionColumnTypeInference.enabled\", \"false\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "coursepool",
              "session_id": "0",
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-02-26T00:08:40.9770308Z",
              "session_start_time": null,
              "execution_start_time": "2024-02-26T00:12:04.0856841Z",
              "execution_finish_time": "2024-02-26T00:12:26.9728523Z",
              "spark_jobs": null,
              "parent_msg_id": "1074bffc-3ecb-4cc7-bc7d-528b138b187c"
            },
            "text/plain": "StatementMeta(coursepool, 0, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "execution_count": 3,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\n",
        "\n",
        "-- Create database to which we are going to write the data\n",
        "\n",
        "CREATE DATABASE IF NOT EXISTS nyc_taxi_ldw_spark\n",
        "LOCATION 'abfss://nyc-taxi-data@synapsecoursedlsam.dfs.core.windows.net/gold';"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "coursepool",
              "session_id": "0",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-02-26T00:08:40.9778257Z",
              "session_start_time": null,
              "execution_start_time": "2024-02-26T00:12:27.1168346Z",
              "execution_finish_time": "2024-02-26T00:12:41.8343462Z",
              "spark_jobs": null,
              "parent_msg_id": "83c92030-adbe-4c6c-be69-2d09c8e8dae6"
            },
            "text/plain": "StatementMeta(coursepool, 0, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Read the silver data to be processed. \n",
        "trip_data_green_df = spark.read.parquet(f\"{silver_folder_path}/trip_data_green\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "coursepool",
              "session_id": "0",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-02-26T00:08:40.97861Z",
              "session_start_time": null,
              "execution_start_time": "2024-02-26T00:12:41.9854879Z",
              "execution_finish_time": "2024-02-26T00:12:42.1326313Z",
              "spark_jobs": null,
              "parent_msg_id": "70cc0f2d-b9a8-497e-9582-3ffd6eb752c5"
            },
            "text/plain": "StatementMeta(coursepool, 0, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Perform the required aggregations\n",
        "# 1. Total trip count\n",
        "# 2. Total fare amount\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "trip_data_green_agg_df = trip_data_green_df \\\n",
        "                        .groupBy(\"year\", \"month\", \"pu_location_id\", \"do_location_id\") \\\n",
        "                        .agg(count(lit(1)).alias(\"total_trip_count\"),\n",
        "                        round(sum(\"fare_amount\"), 2).alias(\"total_fare_amount\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "coursepool",
              "session_id": "0",
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-02-26T00:08:40.9796757Z",
              "session_start_time": null,
              "execution_start_time": "2024-02-26T00:12:42.2787072Z",
              "execution_finish_time": "2024-02-26T00:13:07.4132618Z",
              "spark_jobs": null,
              "parent_msg_id": "ea78db93-8381-4a8e-83cd-5224aa5d3659"
            },
            "text/plain": "StatementMeta(coursepool, 0, 7, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Write the aggregated data to the gold table for consumption\n",
        "\n",
        "trip_data_green_agg_df.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").format(\"parquet\").saveAsTable(\"nyc_taxi_ldw_spark.trip_data_green_agg\")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}